services:
  kafka-controller:
    image: apache/kafka:3.9.1
    container_name: kafka-controller
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: controller
      KAFKA_LISTENERS: CONTROLLER://:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-controller:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    networks:
      - f1-network

  kafka-broker:
    image: apache/kafka:3.9.1
    container_name: kafka-broker
    depends_on:
      - kafka-controller
    environment:
      KAFKA_NODE_ID: 2
      KAFKA_PROCESS_ROLES: broker
      KAFKA_LISTENERS: PLAINTEXT://:19092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:19092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka-controller:9093
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    healthcheck:
      test: ["CMD", "/opt/kafka/bin/kafka-topics.sh", "--bootstrap-server", "kafka-broker:19092", "--list"]
      interval: 1s
      timeout: 5s
      retries: 10
    networks:
      - f1-network

  kafka-init:
    image: apache/kafka:3.9.1
    container_name: kafka-init
    depends_on:
      kafka-broker:
        condition: service_healthy
    entrypoint: [ '/bin/sh', '-c' ]
    command: |
      "
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka-broker:19092 --create --if-not-exists --topic f1-telemetry-lap --replication-factor 1 --partitions 2
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka-broker:19092 --create --if-not-exists --topic f1-telemetry-car-telemetry --replication-factor 1 --partitions 2
      "
    networks:
      - f1-network

  spark-master:
    build:
      context: spark
      dockerfile: Dockerfile
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_MASTER_HOST=spark-master
    depends_on:
      - kafka-broker
    networks:
      - f1-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 1s
      timeout: 5s
      retries: 10

  spark-worker:
    build:
      context: spark
      dockerfile: Dockerfile
    depends_on:
      - spark-master
      - kafka-broker
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2g
    networks:
      - f1-network
    deploy:
      replicas: 1

  f1-telemetry-producer:
    container_name: f1-telemetry-producer
    build:
      context: producer
      dockerfile: Dockerfile
    depends_on:
      kafka-init:
        condition: service_completed_successfully
    environment:
      - RUST_LOG=debug
      - UDP_URL=0.0.0.0
      - UDP_PORT=20777
      - KAFKA_BOOTSTRAP_SERVERS=kafka-broker:19092
      - LAP_TOPIC=f1-telemetry-lap
      - CAR_TELEMETRY_TOPIC=f1-telemetry-car-telemetry
    networks:
      - f1-network

  f1-telemetry-consumer:
    container_name: f1-telemetry-consumer
    build:
      context: consumer
      dockerfile: Dockerfile
    environment:
      - KAFKA_BROKER=kafka-broker:19092
      - LAP_TOPIC=f1-telemetry-lap
      # - SPARK_MASTER_URL=spark://spark-master:7077 TODO
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      spark-master:
        condition: service_healthy
    networks:
      - f1-network

networks:
  f1-network:
    driver: bridge
